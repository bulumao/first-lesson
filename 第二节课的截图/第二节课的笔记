1.进入开发机和后，配置所需要的环境，使用pip指令完成对环境包的安装。
2.下载InternLM2-Chat-1.8B 模型。创建文件目录demo并进入，然后下载模型参数文件。
	运行cli_demo.
	创建虚拟环境demo，然后在环境中运行模型。
	当出现User >>>时程序已经运行成功，我们输入“请创作一个300字的小故事"后，模型会执行该命令然后打印出一篇小故事。
3.使用八戒chat-1.8B模型.
	激活虚拟环境demo，进入root文件夹，使用git命令来获取demo文件。
	下载并运行chet-八戒demo。下载完后，按下win'+r键打开本地的powershell，查询开发机的端口，即ssh命令
	在本机使用ssh链接studio端口，再将密钥输入到终端里即可链接，然后可以在本地运行八戒。
4.使用 Lagent 运行 InternLM2-Chat-7B 模型。
	首页升级开发机配置，开启30%A100权限。
	激活demo虚拟环境，打开文件子路径，使用git命令克隆lagent相关的代码库。
	打开lagent，正在终端输入命令，构造软连接快捷访问方式，然后打开examples/internlm2_	agent_web_demo_hf.py 文件并修改代码。
	点击6006端口链接，加载模型。在加载的同时在本地创建ssh链接，这一步的意义主要是能远程连接虚拟机，在	本地跑模型。操作步骤如上。
5.使用浦语.灵笔2模型。
	首先升级开发机配置，升级到50%A100.启动conda里的demo虚拟环境。下载 InternLM-XComposer 仓库 相	关的代码资源，然后在终端中输入命令，构造软链接访问。
	输入指令来启动InternLM-XComposer，然后在本机链接ssh端口。
	最后打开网站链接。
	重新打开一个终端，启动InternLM-XComposer2-vl，点开网站后上传图片分析内容。
