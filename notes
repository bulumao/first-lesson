  大模型已经成为了发展AGI的重要途径，有专用模型，即针对特定任务，一个模型解决一个问题如围棋比赛，转变成了通用大模型，即一个模型应对多种任务，如现在的Chat-4。
  体系：LnternLM2-BAse作为高质量且具有很强可塑性的基座，是模型进行深度领域适配的起点，而该基座里面有7B和12B两类模型。7B供给轻量级的研究且模型的性能不俗。20B模型的综合能力更强，至支持更加复杂的场景。在此基座的基础上，又有InternLM2
和InternLM2-Chat。
    (1)InternLM2在Base的基础上对多个能力进行了优化，在测评中表现优异，同时保持了很好的通用语言能力。
    (2)InternLM2-Chat则是在Base的基础上经过SFT和RLHF，面向对话交互进行了优化。是一款具有很好的指令遵循和聊天的一个模型。
  回归语言的本质；利用高质量的语料去使模型去学会建模能力。
  那我们怎么样去筛选高质量的语料呢？
    (1)使用新一代数据清洗过滤技术，采用基于本文质量，信息质量，信息密度等多维度的方面对数据的价值进行1综合评估与提升。
    (2)通过高质量的语料驱动这种数据富集的方式从互联网，语料库里面去进行进一步的复习。、
    (3)针对性的数据补齐来加强模型对于世界知识，处理代码上存在的一些差异能力差异
  可见InterLM2的整体数据处理能力是强于初代的
InternLM2的主要亮点：
  (1)超长的上下文链接：在20万的token上下文中，几乎完美实现了“大海捞针”的测试。
  (2)综合性能的全面提升：测试结果比肩Chat-3.5
  (3)优秀的对话和创作体验：充满人文关怀的对话，如首先，其次等
  (4)工具调用能力整体升级：多工机具的组合调用
  (5)突出的数理能力和实用的数据分析功能：强大的内生计算能力，借助代码解释器可以进一步提升数学成绩。在math方面借助解释器甚至可以超过chat-4
  从模型到应用：由这个InternLM2这个模型希望去构建智能客服，个人助手和行业应用以及各种各样的应用也需要经历很多环节。
如：(1)模型的选型（评测），选择一个或几个在业务场景里去考虑。
    (2)业务场景是否复杂？
    (3)算力是否充足？
    (4)对模型进行评估。是否需要与环境交互人，然后构建智能体。
    (5)在预期领域里做进一步的评测
    (6)模型的部署和上线。这里或许会设计许多代码的开发。
  现在已经在社区开源了全链路的体系：有书生.万卷的数据库，预训练上有InternLM-train还有XTuner的微调。在部署上开源了
LMDeploy，测评上开源了open Compass（司南），应用上支持多智能体和支持智能体的工具箱。
  数据集方面：总数居量达到了2tb，且都是符合中国价值观的中文语料，有图像文本数据和视频数据。而书生.万卷cc则是涵盖了2013-2023年的互联网数据，且对这些数据进行了清洗
在安全方面做了较多的处理。
  预训练的层面：开发了预训练框架，具备高可扩展性。
  微调方面：开发了XTuner的框架，增量续训和有监督微调是下游应用微调的两种方式。增量续训是采用类似于预训练的方式让模型学到一些新知识，数据可以是书籍，文章代码等。
    有监督的微调主要是让模型学会理解各种指令来进行对话，或者利用这种方式来注入少量的领域知识，这里的数据就是高质量的对话或者问答数据。微调也分为全量参数微调和部分参数微调（降低成本）
  评测：compass Rank提供中立全面的性能榜单，包括大语言模型和多模态模型的榜单。
      compasskit：大模型的评测的全栈工具链
      compasshub：高质量评测集社区
  部署：开发了LMDeploy这种大模型全流程的部署解决方案，包括了模型的轻量化推理和服务等。提供了各种接口，如python
智能体的框架：。
  开发了一个智能体框架lagent，支持多种智能体的能力和多种大语言模型，也会有很多内置工具可供使用。除此之外还开发了多模态智能体的工具箱AgentLego
他主要是丰富的工具集合。
